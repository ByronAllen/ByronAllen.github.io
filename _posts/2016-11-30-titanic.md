---
layout: post
title: Who Survived the Titanic?
---


The Titanic dataset is a staple of early learning in data analytics and data science. I investigated the key contributors to survival and developed a model to predict what an individual's fate would be based on available contextual data.

After connecting to a remote PostgreSQL database, I placed the Titanic dataset into a Panda dataframe for cleaning. I noticed the fields of Sex, Age, Cabin and Embarked require attention:
* **Sex**: Transformed the categorical values in Sex to binary values
* **Age**: Filled Nan values in Age with the mean age from
* **Cabin**: Simplified cabin identification, but ultimately opted to drop this field as there are too few values
* **Embarked**: Transformed the categorical values into numerical values

After cleaning the dataset, I created my X variable that includes the 'contextual' data of each passenger and my target, or 'y', variable.
* **Fields in X:** Pclass, Male, Age, SibSp, Parch, Fare, Embarked
* **Target y:** Survived

I experimented with several models and found that Logistic Regression optimized with a GridSearch (lr_gs) and Random Forest optimized with a GridSearch (rf_gs) produced the highest average accuracy; 0.80 and 0.82 respectively. Initial indications suggest that rf_gs is the best model to predict the survival of an individual on the Titanic.

![_config.yml]({{ site.baseurl }}/images/titanic_roc.png)

After analyzing the models with a ROC curve it is clear that lr_gs provides a more precise prediction than rf_gs. In other words, both models are similarly accurate in predicting who will survive on the Titanic, yet the rf_gs model makes more incorrect predictions, thus making lr_gs the best model to leverage when making a prediction on this dataset.

Click [here](https://github.com/ByronAllen/Portfolio/blob/master/GA_DSI_Project%205.ipynb) to see the full notebook.

